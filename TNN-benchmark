#!/usr/bin/env python3
"""
Topological Neural Network — Multi-Dataset Training
MHD closure with curvature coupling 
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"✓ Using device: {device}")

# ===============================================================
# Core Stable Topological Layer
# ===============================================================

class StableTopoLinear(nn.Module):
    def __init__(self, inp, out, eta=0.001, target_energy=1e-4):
        super().__init__()
        self.fc = nn.Linear(inp, out)
        self.eta = eta
        self.target_energy = target_energy
        self.register_buffer('alpha', torch.randn(out, inp) * 0.001)
        self.register_buffer('beta', torch.randn(out, inp) * 0.001)
        self.register_buffer('c_field', torch.ones(out, inp) * 0.1)

        self.energy_hist, self.coupling_hist, self.stability_hist = [], [], []
        self.prev_energy = None

    def safe_div(self, num, den, eps=1e-6):
        return num / torch.clamp(den, min=eps)

    def mhd_update(self, weights):
        with torch.no_grad():
            self.alpha = torch.clamp(self.alpha, -10, 10)
            self.beta = torch.clamp(self.beta, -10, 10)
            self.c_field = torch.clamp(self.c_field, 0.01, 10)

            S_alpha = self.eta * self.safe_div(self.alpha, self.c_field**2)
            S_beta = self.eta * self.safe_div(self.beta, self.c_field**2)
            mod = 0.001 * torch.randn_like(self.alpha)
            self.alpha += 0.1 * (S_alpha + mod)
            self.beta += 0.1 * (S_beta - mod)

            energy = 0.5 * (self.alpha**2 + self.beta**2).mean().item()
            if self.prev_energy is None:
                stability = 0.0
            else:
                stability = abs(energy - self.prev_energy)
            self.prev_energy = energy

            coupling = (self.alpha * self.beta).abs().mean().item()
            self.energy_hist.append(energy)
            self.coupling_hist.append(coupling)
            self.stability_hist.append(stability)
            return energy, coupling, stability

    def forward(self, x):
        out = self.fc(x)
        self.mhd_update(self.fc.weight)
        return out

# ===============================================================
# Network wrapper
# ===============================================================

class StableTopologicalNN(nn.Module):
    def __init__(self, input_dim=784, hidden=256, classes=10):
        super().__init__()
        self.layer1 = StableTopoLinear(input_dim, hidden, eta=0.001)
        self.layer2 = StableTopoLinear(hidden, classes, eta=0.0005)

    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = F.relu(self.layer1(x))
        return self.layer2(x)

    # --- NaN-safe metrics fix ---
    def metrics(self):
        def safe_mean(vals):
            vals = [v for v in vals if not np.isnan(v)]
            return np.mean(vals) if len(vals) > 0 else 0.0

        e = safe_mean(self.layer1.energy_hist[-5:] + self.layer2.energy_hist[-5:])
        c = safe_mean(self.layer1.coupling_hist[-5:] + self.layer2.coupling_hist[-5:])
        s = safe_mean(self.layer1.stability_hist[-5:] + self.layer2.stability_hist[-5:])
        return e, c, s

# ===============================================================
# Baseline model
# ===============================================================

class BaselineMLP(nn.Module):
    def __init__(self, input_dim=784, hidden=256, classes=10):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden)
        self.fc2 = nn.Linear(hidden, classes)
    def forward(self, x):
        x = x.view(x.size(0), -1)
        x = F.relu(self.fc1(x))
        return self.fc2(x)

# ===============================================================
# Dataset loader
# ===============================================================

def get_dataset(name, batch=128):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    if name == "MNIST":
        train = datasets.MNIST("/tmp", train=True, download=True, transform=transform)
        test = datasets.MNIST("/tmp", train=False, transform=transform)
    elif name == "FashionMNIST":
        train = datasets.FashionMNIST("/tmp", train=True, download=True, transform=transform)
        test = datasets.FashionMNIST("/tmp", train=False, transform=transform)
    elif name == "KMNIST":
        train = datasets.KMNIST("/tmp", train=True, download=True, transform=transform)
        test = datasets.KMNIST("/tmp", train=False, transform=transform)
    elif name == "CIFAR10":
        transform = transforms.Compose([
            transforms.Grayscale(),
            transforms.Resize((28,28)),
            transforms.ToTensor(),
            transforms.Normalize((0.5,), (0.5,))
        ])
        train = datasets.CIFAR10("/tmp", train=True, download=True, transform=transform)
        test = datasets.CIFAR10("/tmp", train=False, transform=transform)
    else:
        raise ValueError(f"Unknown dataset {name}")
    return (DataLoader(train, batch_size=batch, shuffle=True),
            DataLoader(test, batch_size=batch))

# ===============================================================
# Training and evaluation
# ===============================================================

def train_epoch(model, loader, opt):
    model.train()
    tot_loss, correct, n = 0, 0, 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        opt.zero_grad()
        out = model(x)
        loss = F.cross_entropy(out, y)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        opt.step()
        tot_loss += loss.item() * x.size(0)
        correct += (out.argmax(1) == y).sum().item()
        n += x.size(0)
    return tot_loss / n, correct / n

@torch.no_grad()
def eval_epoch(model, loader):
    model.eval()
    tot_loss, correct, n = 0, 0, 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        out = model(x)
        loss = F.cross_entropy(out, y)
        tot_loss += loss.item() * x.size(0)
        correct += (out.argmax(1) == y).sum().item()
        n += x.size(0)
    return tot_loss / n, correct / n

# ===============================================================
# Run per-dataset experiment
# ===============================================================

def run_dataset(name):
    print("\n" + "="*70)
    print(f"DATASET: {name}")
    print("="*70)

    train_loader, test_loader = get_dataset(name)
    baseline = BaselineMLP().to(device)
    topo = StableTopologicalNN().to(device)
    opt_b = torch.optim.Adam(baseline.parameters(), lr=0.001)
    opt_t = torch.optim.Adam(topo.parameters(), lr=0.001)

    results = {"baseline": [], "topo": [], "energy": [], "coupling": [], "stability": []}

    for epoch in range(1, 21):
        train_epoch(baseline, train_loader, opt_b)
        train_epoch(topo, train_loader, opt_t)
        _, acc_b = eval_epoch(baseline, test_loader)
        _, acc_t = eval_epoch(topo, test_loader)
        e, c, s = topo.metrics()
        results["baseline"].append(acc_b)
        results["topo"].append(acc_t)
        results["energy"].append(e)
        results["coupling"].append(c)
        results["stability"].append(s)
        print(f"Epoch {epoch:2d}/20: Base={acc_b:.4f}, Topo={acc_t:.4f}, E={e:.6f}, C={c:.6f}, S={s:.6f}")

    # Save plots
    os.makedirs("outputs", exist_ok=True)
    fig, axes = plt.subplots(1,3, figsize=(14,4))
    axes[0].plot(results["baseline"], label="Baseline")
    axes[0].plot(results["topo"], label="Topo")
    axes[0].set_title(f"Accuracy ({name})"); axes[0].legend()
    axes[1].plot(results["energy"], 'g-'); axes[1].set_title("Energy")
    axes[2].plot(results["stability"], 'b-'); axes[2].set_title("Stability")
    plt.tight_layout()
    plt.savefig(f"outputs/topo_results_{name}.png", dpi=150)
    print(f"✓ Saved plot: outputs/topo_results_{name}.png")

    # Save CSV
    np.savetxt(f"outputs/{name}_metrics.csv",
               np.column_stack([results["baseline"], results["topo"],
                                results["energy"], results["coupling"], results["stability"]]),
               delimiter=",", header="baseline,topo,energy,coupling,stability", comments="")
    print(f"✓ Saved metrics: outputs/{name}_metrics.csv")

# ===============================================================
# Main execution
# ===============================================================

if __name__ == "__main__":
    for ds in ["MNIST", "FashionMNIST", "KMNIST", "CIFAR10"]:
        run_dataset(ds)
    print("\nAll datasets complete — metrics and plots saved in /outputs/")
